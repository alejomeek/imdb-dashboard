# ğŸ¬ IMDb Analytics Dashboard

Dashboard interactivo de anÃ¡lisis de pelÃ­culas y series usando datos pÃºblicos de IMDb. Proyecto acadÃ©mico de visualizaciÃ³n de datos sobre la industria audiovisual.

## ğŸ“Š CaracterÃ­sticas

- **AnÃ¡lisis temporal**: EvoluciÃ³n de la producciÃ³n audiovisual desde 1950
- **GÃ©neros**: Tendencias y popularidad de gÃ©neros cinematogrÃ¡ficos
- **Personas**: Top directores y actores mÃ¡s prolÃ­ficos y mejor valorados
- **GeografÃ­a**: AnÃ¡lisis de producciÃ³n por paÃ­ses
- **Series**: Estructura de temporadas y episodios

## ğŸš€ TecnologÃ­as

- **Backend**: Python 3.9+
- **ETL**: DuckDB (procesamiento eficiente de archivos grandes)
- **VisualizaciÃ³n**: Streamlit + Plotly
- **Datos**: IMDb Public Datasets
- **Formato**: Parquet (compresiÃ³n ZSTD)

## ğŸ“ Estructura del proyecto

```
imdb-dashboard/
â”œâ”€â”€ app.py                      # AplicaciÃ³n Streamlit
â”œâ”€â”€ etl_imdb.py                 # Pipeline ETL con DuckDB
â”œâ”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ data_raw/                   # Archivos originales de IMDb (local, no en Git)
â”‚   â”œâ”€â”€ title.basics.tsv.gz
â”‚   â”œâ”€â”€ title.ratings.tsv.gz
â”‚   â”œâ”€â”€ title.crew.tsv.gz
â”‚   â”œâ”€â”€ title.principals.tsv.gz
â”‚   â”œâ”€â”€ name.basics.tsv.gz
â”‚   â”œâ”€â”€ title.akas.tsv.gz
â”‚   â””â”€â”€ title.episode.tsv.gz
â””â”€â”€ data_processed/             # Archivos procesados (en Git)
    â”œâ”€â”€ titles_clean.parquet
    â”œâ”€â”€ genres_by_year.parquet
    â”œâ”€â”€ directors.parquet
    â”œâ”€â”€ actors.parquet
    â”œâ”€â”€ countries.parquet
    â””â”€â”€ episodes.parquet
```

## ğŸ”§ InstalaciÃ³n y uso local

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/imdb-dashboard.git
cd imdb-dashboard
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Descargar datos de IMDb (opcional, si quieres regenerar los datasets)

```bash
mkdir data_raw
cd data_raw

# Descargar archivos desde https://datasets.imdbws.com/
wget https://datasets.imdbws.com/title.basics.tsv.gz
wget https://datasets.imdbws.com/title.ratings.tsv.gz
wget https://datasets.imdbws.com/title.crew.tsv.gz
wget https://datasets.imdbws.com/title.principals.tsv.gz
wget https://datasets.imdbws.com/name.basics.tsv.gz
wget https://datasets.imdbws.com/title.akas.tsv.gz
wget https://datasets.imdbws.com/title.episode.tsv.gz

cd ..
```

### 4. (Opcional) Ejecutar el pipeline ETL

Si descargaste los datos originales y quieres regenerarlos:

```bash
python etl_imdb.py
```

Este proceso puede tomar entre 10-30 minutos dependiendo de tu hardware. GenerarÃ¡ los archivos `.parquet` optimizados en `data_processed/`.

### 5. Ejecutar la aplicaciÃ³n

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ en tu navegador en `http://localhost:8501`

## â˜ï¸ Deployment en Streamlit Cloud

### Requisitos previos

1. Cuenta en [Streamlit Cloud](https://streamlit.io/cloud)
2. Repositorio en GitHub con los archivos `.parquet` procesados

### Pasos

1. **Subir el cÃ³digo a GitHub**:
   ```bash
   git add .
   git commit -m "Initial commit"
   git push origin main
   ```

2. **Configurar en Streamlit Cloud**:
   - Ve a [share.streamlit.io](https://share.streamlit.io)
   - Click en "New app"
   - Selecciona tu repositorio
   - Main file: `app.py`
   - Click en "Deploy"

3. **Importante**: AsegÃºrate de que los archivos `.parquet` estÃ©n en el repositorio dentro de la carpeta `data_processed/`

## ğŸ“Š Datasets procesados

Los archivos Parquet incluyen:

### `titles_clean.parquet`
TÃ­tulos principales con ratings filtrados (mÃ­nimo 1000 votos, aÃ±os 1950-2024)

**Columnas**: 
- `tconst`, `titleType`, `primaryTitle`, `originalTitle`
- `startYear`, `endYear`, `runtimeMinutes`, `genres`
- `averageRating`, `numVotes`

### `genres_by_year.parquet`
AgregaciÃ³n de gÃ©neros por aÃ±o

**Columnas**: 
- `startYear`, `genre`, `titleType`
- `count`, `avg_rating`, `total_votes`

### `directors.parquet`
RelaciÃ³n directores-tÃ­tulos

**Columnas**: 
- `tconst`, `nconst`, `directorName`
- `primaryTitle`, `startYear`, `titleType`
- `averageRating`, `numVotes`

### `actors.parquet`
RelaciÃ³n actores-tÃ­tulos (top 5 por tÃ­tulo)

**Columnas**: 
- `tconst`, `nconst`, `actorName`, `category`, `ordering`
- `primaryTitle`, `startYear`, `titleType`
- `averageRating`, `numVotes`

### `countries.parquet`
ProducciÃ³n por paÃ­s

**Columnas**: 
- `tconst`, `region` (cÃ³digo ISO)
- `primaryTitle`, `startYear`, `titleType`, `genres`
- `averageRating`, `numVotes`

### `episodes.parquet`
Estructura de series y episodios

**Columnas**: 
- `episodeId`, `seriesId`, `seasonNumber`, `episodeNumber`
- `episodeTitle`, `episodeYear`, `episodeRating`, `episodeVotes`
- `seriesTitle`, `seriesStartYear`

## ğŸ¯ Filtros aplicados en el ETL

- **AÃ±os**: 1950-2024
- **Votos mÃ­nimos**: 1,000
- **Contenido adulto**: Excluido (`isAdult = 0`)
- **Tipos de contenido**: movie, tvSeries, tvMovie, tvEpisode, tvMiniSeries
- **Actores**: Solo los 5 principales por tÃ­tulo

## ğŸ“ˆ Optimizaciones

- **DuckDB**: Procesamiento 10-20x mÃ¡s rÃ¡pido que pandas puro
- **Parquet + ZSTD**: CompresiÃ³n eficiente (reducciÃ³n ~70% vs CSV)
- **Filtrado temprano**: ReducciÃ³n de datos antes de joins
- **Lazy loading**: Streamlit carga solo los datos necesarios

## ğŸ” Ejemplo de uso del ETL

```python
import duckdb

# Conectar
con = duckdb.connect()

# Query de ejemplo
result = con.execute("""
    SELECT 
        startYear,
        COUNT(*) as num_movies
    FROM read_parquet('data_processed/titles_clean.parquet')
    WHERE titleType = 'movie'
    GROUP BY startYear
    ORDER BY startYear
""").df()

print(result)
```

## ğŸ“ Notas importantes

### Para desarrollo local

1. Los archivos originales de IMDb (`data_raw/`) **NO** deben subirse a Git
2. AÃ±ade `data_raw/` a `.gitignore`
3. Solo sube los archivos procesados (`data_processed/*.parquet`)

### Limitaciones de tamaÃ±o

- GitHub: 100 MB por archivo
- Streamlit Cloud (free tier): ~1 GB RAM
- Si los archivos superan estos lÃ­mites, considera:
  - Filtros mÃ¡s agresivos (mÃ¡s votos, menos aÃ±os)
  - Split en mÃºltiples archivos
  - Usar Git LFS para archivos grandes

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico. Si encuentras errores o tienes sugerencias:

1. Abre un Issue
2. EnvÃ­a un Pull Request

## ğŸ“„ Licencia

Este proyecto usa datos pÃºblicos de IMDb. Por favor, revisa las [condiciones de uso de IMDb](https://www.imdb.com/conditions).

## ğŸ”— Enlaces Ãºtiles

- [IMDb Datasets](https://datasets.imdbws.com/)
- [DocumentaciÃ³n IMDb Datasets](https://www.imdb.com/interfaces/)
- [Streamlit Docs](https://docs.streamlit.io/)
- [DuckDB Docs](https://duckdb.org/docs/)
- [Plotly Python](https://plotly.com/python/)

## ğŸ“§ Contacto

Para preguntas sobre el proyecto, abre un Issue en GitHub.

---

**âš ï¸ Disclaimer**: Este dashboard es solo para fines educativos. Los datos pertenecen a IMDb y estÃ¡n sujetos a sus tÃ©rminos de uso.